{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation in science\n",
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/KEMM30_007.png\" width=\"600\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you get there? or better,how do you get there without producing a lot of nonsense\n",
    "Counting parameter. e.g. 10 peaks, each position, width, intensity =30 parameter plus background. So fitting is about intelligence. Think, $\\textbf{optimize}$ the smallest amount of parameter starting with a good guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One parameter optimisation (middle = mu)\n",
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/error_way.png\" width=\"1000\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/KEMM30_008.jpg\" width=\"900\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can go into optimisation we have to talk about \n",
    "\n",
    "# Functions:\n",
    "\n",
    "Two ways to define functions: the classical way using def a more compact way is using a so-called lambda function. We will focus on the definition only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function():  #my_function is the name of the function. The brackets are mandatory \n",
    "    print('Hello World')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the above command you only define a function, but do not execute it. this you do by writing the function name with round brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function2(s):  #this function has an input\n",
    "    print(s)\n",
    "my_function2(s='Hello world') #call the function with defined parameter\n",
    "my_function2('Hello world') # or position parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "important, what is in a function stays in a function. meaning this line will give an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function2(s):  #this function has an input\n",
    "    a_parameter=5\n",
    "a_parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you want to use something out of a function you have to return it. Usually you would assign the returned value to a variable, here \"catch_the_output\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function3(s): \n",
    "    return s+1\n",
    "catch_the_output=my_function3(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function4(s): \n",
    "    '''this fucntion returns multiple things'''\n",
    "    return s,s+1\n",
    "catch_the_output1,catch_the_output2=my_function4(10)\n",
    "print(catch_the_output1,' and ', catch_the_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Write a standard function that takes x, mu and sigma and returns a gaussian bell curve (with normalisation). Make sure that you use numpy operations only, so that you can give it a vector and receive a vector.<br> \n",
    "${\\frac {1}{\\sqrt {2\\pi \\sigma ^{2}}}}\\operatorname {exp} \\left(-{\\frac {\\left(x-\\mu \\right)^{2}}{2\\sigma ^{2}}}\\right)$\n",
    "* plot this function with mu=0,sigma=1 from -5 to 5 in 0.01 steps \n",
    "\n",
    "* Write a function that returns the normalized vector \n",
    "* use the cumsum function from numpy to create the cummulative sum of the gaussian from above and normalize it with your lambda function\n",
    "* Plot this in the same plot (against x)\n",
    "* What does this resemble?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter optimisation: Fitting vs. optimisation\n",
    "\n",
    "\n",
    "## Curve Fit\n",
    "Starting with curve_fit. We assume that we have a flat function that has a clear gradient to the minimum (see top of this page) then we can use curve_fit to fast measure the parameter we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = lambda x,mu=0,sigma=1,offset=0: 1/np.sqrt(2*np.pi*(sigma**2))*np.exp((-0.5/sigma**2)*(np.subtract(x,mu))**2)+offset\n",
    "                                    \n",
    "#create some data with some randomness and plot it\n",
    "x=np.linspace(-5,5,200)\n",
    "y=gauss(x,mu=0.5,sigma=0.5)+0.1*np.random.random(np.shape(x))\n",
    "fig,ax=plt.subplots()\n",
    "ax.plot(x,y,'o',ms=2,label='data')\n",
    "ax.set_xlabel('measured value')\n",
    "ax.set_ylabel('occurance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "#make a guess\n",
    "p0=[1,1,0.1]\n",
    "\n",
    "#optimise\n",
    "popt,pcov = curve_fit(gauss, xdata=x, ydata=y,p0=p0)\n",
    "\n",
    "#plot both\n",
    "ax.plot(x, gauss(x, mu=p0[0],sigma=p0[1],offset=p0[2]), 'b-', label='guess')\n",
    "ax.plot(x, gauss(x, mu=popt[0],sigma=popt[1],offset=popt[2]), 'r-', label='fit')\n",
    "ax.legend()\n",
    "\n",
    "#get errors from the covariance matrix (works here, but careful)\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "df=pd.DataFrame({'values':popt,'errors':perr},index=['$\\mu$','$\\sigma$','$x_0$'])\n",
    "df=df[['values','errors']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key bit\n",
    "```\n",
    "from scipy.optimize import curve_fit\n",
    "popt,pcov = curve_fit(gauss, xdata=x, ydata=y,p0=[1,0.5,0.1])\n",
    "```\n",
    "curve fit is a least square method that takes a function, the target data and a set of starting parameters, that are in order the parameter after the first.\n",
    "it returns: \n",
    "popt = optimized parameter\n",
    "and\n",
    "pcov = covariance matrix.\n",
    "p_sigma = np.sqrt(np.diag(pcov))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/KEMM30_009.jpg\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "\n",
    "Read the file, Fit the file, plot both, data and fits:\n",
    "What is the center position of the peak\n",
    "http://www.jensuhlig.de/Kemm30/fit_0.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy minimize\n",
    "\n",
    "Second way of optimisation uses in addition to the \"cost function\" an \"error function\". The task of the second function is to create a \"price\" for this parameter. The Minimize function is then minimizing this price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x,p): #the function that is your model\n",
    "    [mu,sigma,offset]=p\n",
    "    pre_factor=1/np.sqrt(2*np.pi*(sigma**2))\n",
    "    exponent=(-0.5/sigma**2)*(np.subtract(x,mu))**2\n",
    "    return pre_factor*np.exp(exponent)+offset\n",
    "x=np.linspace(-5,5,200)\n",
    "y=gauss(x,[0.5,0.5,0.2])\n",
    "y=y+(y**0.5)*0.5*np.random.random(np.shape(x))\n",
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "ax.plot(x,y,'o',ms=5,label='data')\n",
    "ax.set_xlabel('measured value')\n",
    "ax.set_ylabel('occurance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new thing is that you need a second function that produces you a single \"error\" value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_gauss(p):# this would be the root mean square (we skip the root as the minimum is the minimum)\n",
    "    return ((y-gauss(x,p))**2).sum()\n",
    "def min_gauss_lin(p): #this is a different cost function that uses a more linear approach. It does not \"punish\" strong deviations as much. As such it has the tendency to be more outlier stable but preforms bad for peaks.\n",
    "    return np.abs(y-gauss(x,p)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize #import the minimization function\n",
    "x0=[1.,0.5,0.1]\n",
    "out = minimize(min_gauss,x0=x0,method='Nelder-Mead') #nelder-Mead is a standard multi-parameter optimiser. check out other choices.\n",
    "out2 = minimize(min_gauss_lin,x0=x0,method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(8,8))\n",
    "ax.plot(x,y,'o',ms=5,label='data')\n",
    "ax.set_xlabel('measured value')\n",
    "ax.set_ylabel('occurance')\n",
    "ax.plot(x, gauss(x, p=x0), color='blue',lw=5,alpha=0.5,label='start')\n",
    "ax.plot(x, gauss(x, p=out['x']), color='red',linestyle='dashed', lw=5,label='fit_sqrt')\n",
    "ax.plot(x, gauss(x, p=out2['x']), color='green',lw=5,zorder=0, label='fit_lin')\n",
    "print(out)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "\n",
    "Read the files, Fit files and plot both, data and fits:\n",
    "* http://www.jensuhlig.de/Kemm30/fit_0.csv\n",
    "* http://www.jensuhlig.de/Kemm30/fit_1.csv  here: try first a separate fit, in which you fit the linear range and then separately the peak.\n",
    "* http://www.jensuhlig.de/Kemm30/fit_3.csv (two peaks and background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the peaks\n",
    "\n",
    "<div>\n",
    "<img src=\"http://www.jensuhlig.de/Kemm30/2D_measured_indicated.png\" width=\"200\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced\n",
    "\n",
    "While scipy minimize is a very useful tool, it is still a bit difficult to handle parameters. A very nice tool that was developed for this lmfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmfit\n",
    "\n",
    "def gauss_with_names(x,par): #the function that is your model\n",
    "    pre_factor=1/np.sqrt(2*np.pi*(par['sigma']**2))\n",
    "    exponent=(-0.5/par['sigma']**2)*(np.subtract(x,par['mu']))**2\n",
    "    return pre_factor*np.exp(exponent)+par['offset']\n",
    "def min_gauss(par,x,y):# this would be the root mean square (we skip the root as the minimum is the minimum)\n",
    "    return ((y-gauss_with_names(x,par))**2).sum()\n",
    "\n",
    "x=np.linspace(-5,5,200)\n",
    "y=gauss(x,[0.5,0.5,0.2])\n",
    "y=y+(y**0.5)*0.5*np.random.random(np.shape(x))\n",
    "\n",
    "\n",
    "#first create a parameter object\n",
    "par=lmfit.Parameters()                                       # create empty parameter object\n",
    "\n",
    "par.add('mu',value=0,vary=True)                                # Add a parameter\n",
    "par.add('sigma',value=0.5,vary=True)\n",
    "par.add('offset',value=0.1,vary=True)\n",
    "\n",
    "mini = lmfit.Minimizer(min_gauss,par,fcn_kws={'x':x,'y':y})\n",
    "results = mini.minimize('nelder')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
